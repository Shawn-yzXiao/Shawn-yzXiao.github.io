<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Research</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<a href="projects.html" class="logo">Back to Gallery</a>
					</header>


				<!-- Main -->
					<div id="main">

						<!-- Post -->
							<section class="post">
								<header class="major">
									<span class="date">Jan 2024 - May 2024</span>
									<span>Language Technology Institute, CMU<br />
										<b>Members: Yunzhong (Shawn) Xiao, Andy Liu, Alex Xie, Leke Onilude</b></span>

									<h2>Multimodal RAG system with Visual Programming</h2>
									
									<p>The project aims to enhance multimodal question-answering capabilities by developing a model that programmatically integrates textual and visual information to generate accurate, context-aware responses.</p>
								</header>

								<h3>WebQA Dataset Overview</h3>
								<div class="image main" style="display: flex; justify-content: center; align-items: center;">
									<img src="images/webqa.jpg" alt="" style="max-width:90%; height:auto;"/>
								</div>
								<ul>
									<li><strong>Purpose & Composition:</strong> Designed to facilitate multimodal question answering by combining text and images, simulating how humans utilize multiple sources to find answers.</li>
									<li><strong>Multimodal Nature:</strong> Requires systems that can process and infer information from both textual content and visual images.</li>
									<li><strong>Challenges Addressed:</strong> Focuses on the complexity of online search, emphasizing the extraction of relevant information from an abundance of multimodal data.</li>
									<li><strong>Dataset Specifics:</strong> Includes comprehensive training, validation, and test sets, supporting the development of robust models capable of multimodal reasoning.</li>
									<li><strong>Evaluation Metrics:</strong> Uses recall, F1 score, and BART Score to evaluate the accuracy, relevance, and fluency of model-generated answers.</li>
								</ul>

								<h3>Proposed Model: Visual Programming + Image Adapter Layer</h3>
								<div class="image main" style="display: flex; justify-content: center; align-items: center;">
									<img src="images/webrag.png" alt="" style="max-width:50%; height:auto;"/>
								</div>
								<p>Our proposed model combines visual programming with an adaptive image understanding layer to enhance the precision and efficiency of multimodal question-answering systems.</p>
								<ul>
									<li><strong>Core Concept:</strong> Integrates a code generation framework with a unique image adapter layer, enhancing the model's ability to reason with multimodal data.</li>
									<li><strong>Functionality:</strong> Generates executable Python code for query responses, utilizing pre-trained encoders for image comprehension and a decoder for code synthesis.</li>
									<li><strong>Expected Outcomes:</strong> Aims to outperform existing approaches in accuracy for visually intensive questions and offers greater interpretability and adaptability in multimodal reasoning.</li>
								</ul>


							</section>

					</div>


				<!-- Copyright -->
					<div id="copyright">
						<ul><li>&copy; Yunzhong Xiao</li>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>